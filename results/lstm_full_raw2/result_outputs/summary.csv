train_loss,val_loss
2.994877,3.0391693
2.7047193,2.850373
2.6048403,3.0111363
2.5440361,2.8352325
2.505725,2.840918
2.4833949,2.730562
2.3991222,2.7480924
2.3875003,2.702044
2.3690543,2.82369
2.3498595,2.782499
2.5802135,2.7491293
2.3463652,2.6921456
2.3688762,2.915084
2.2948036,3.1220913
2.3494573,2.6437256
2.3656244,2.7402093
2.2795343,2.6684248
2.295065,2.5816565
2.246168,2.646014
2.2109196,2.724216
2.1751797,2.745437
2.157029,2.6006086
2.1786208,2.6716826
2.1217706,2.7590091
2.1578426,2.5644498
2.0848398,2.561273
2.251743,2.6488867
2.0928812,2.7543018
2.0806048,3.3979473
2.1102173,2.783926
2.0303829,2.6045258
2.0504746,2.5810072
2.022244,2.5706763
2.0301466,2.8566775
2.0256205,2.627135
2.0325322,2.650508
2.0343413,2.5784152
1.9876277,2.6976566
1.9849496,2.588797
1.9871169,2.6412928
1.9741288,2.650496
1.9684991,2.610102
1.948654,2.6380315
1.954381,2.6557562
1.9603623,2.658156
1.9562591,2.6433523
1.9180993,2.7105079
1.9180053,2.623848
1.9216809,2.6412082
1.8788319,2.7369208
1.9061607,2.6728208
1.8887024,2.6686296
1.8761245,2.6794326
1.9006411,2.7697918
1.9030334,2.796501
1.8763714,2.6697447
1.8689051,2.7654524
1.8437427,2.6299994
1.832562,2.605489
1.8381494,2.6826391
1.833578,2.5903106
1.8116587,2.6602156
1.8544849,2.6800532
1.800627,2.5927866
1.8238893,2.7021916
1.7917353,2.6440248
1.8028172,2.686689
1.7873446,2.627625
1.8115575,2.7760735
1.7573947,2.7462163
1.7617097,2.7209656
1.7835119,2.6832182
1.7423923,2.7229788
1.7761827,2.703849
1.7606777,2.664394
1.7301235,2.7241135
1.7613728,2.6543589
1.7382883,2.6653185
1.7188301,2.664429
1.7050148,2.750721
